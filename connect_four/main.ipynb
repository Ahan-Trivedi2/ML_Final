{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (1.10.1)\n",
      "Collecting scipy\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/ea/c2/5ecadc5fcccefaece775feadcd795060adf5c3b29a883bff0e678cfe89af/scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from scipy) (2.0.2)\n",
      "Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/44.8 MB 17.8 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 2.1/44.8 MB 26.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 3.2/44.8 MB 25.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 4.3/44.8 MB 27.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.9/44.8 MB 22.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 5.8/44.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.8/44.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 7.7/44.8 MB 21.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.7/44.8 MB 21.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.8/44.8 MB 21.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 11.2/44.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 12.6/44.8 MB 22.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.1/44.8 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 15.5/44.8 MB 25.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.1/44.8 MB 27.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.6/44.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 20.0/44.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 21.7/44.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 23.8/44.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 25.3/44.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 26.8/44.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 28.3/44.8 MB 32.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 29.8/44.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.4/44.8 MB 34.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.8/44.8 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.3/44.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.5/44.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.1/44.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.6/44.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.1/44.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.5/44.8 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.0/44.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.5/44.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.8/44.8 MB 31.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.8/44.8 MB 31.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 MB 24.2 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\nsingh\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages\\\\~cipy\\\\sparse\\\\_sparsetools.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy<2\n",
    "!pip install --upgrade scipy\n",
    "!pip install pybind11>=2.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import tkinter\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image\n",
    "\n",
    "root = tkinter.Tk()\n",
    "#Setting it up\n",
    "keno = ImageTk.PhotoImage(Image.open(\"./keno.png\"))\n",
    "red = ImageTk.PhotoImage(Image.open(\"./kokkino.png\"))\n",
    "blue = ImageTk.PhotoImage(Image.open(\"./ble.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same(a):\n",
    "    \n",
    "    for i in range( len(a) ):\n",
    "        if a[0] != a[i]:\n",
    "            return ( False )\n",
    "        \n",
    "    return ( True )\n",
    "\n",
    "#reverse state for 2nd agent, so that it can make predictions according to what the 1st agent has learned so far\n",
    "def rev( a ):\n",
    "    b = a.copy()\n",
    "    b[ a == 1 ] = 2\n",
    "    b[ a == 2 ] = 1\n",
    "    return ( b.copy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.R, self.C = 6,7\n",
    "        self.board = np.zeros( (self.R,self.C), dtype='uint8' )\n",
    "    \n",
    "    def reset(self):\n",
    "        for i in range( self.R ):\n",
    "            for j in range( self.C ):\n",
    "                self.board[i][j] = 0\n",
    "    \n",
    "    def step(self,who,action):\n",
    "        \n",
    "        placed = False\n",
    "        for j in range( self.R-1, -1, -1 ):\n",
    "            if self.board[j][action] == 0:\n",
    "                self.board[j][action] = who\n",
    "                placed = True\n",
    "                break\n",
    "        \n",
    "        return ( placed )\n",
    "    \n",
    "    def getState(self):\n",
    "        return self.board.copy()\n",
    "    \n",
    "    def isFinal(self):\n",
    "        \n",
    "        #check horizontal\n",
    "        for i in range( self.R ):\n",
    "            for j in range( self.C ):\n",
    "                if self.board[i][j] != 0:\n",
    "                    x, y = i, j\n",
    "                    a = []\n",
    "                    for k in range(4):\n",
    "                        a.append( self.board[x][y] )\n",
    "                        y += 1\n",
    "                        if y >= self.C:\n",
    "                            break\n",
    "                    if same( np.array(a) ) and len(a) == 4:\n",
    "                        return ( a[0] )\n",
    "                \n",
    "        #check vertical\n",
    "        for i in range( self.R ):\n",
    "            for j in range( self.C ):\n",
    "                if self.board[i][j] != 0:\n",
    "                    x, y = i, j\n",
    "                    a = []\n",
    "                    for k in range(4):\n",
    "                        a.append( self.board[x][y] )\n",
    "                        x += 1\n",
    "                        if x >= self.R:\n",
    "                            break\n",
    "                    if same( np.array(a) ) and len(a) == 4:\n",
    "                        return ( a[0] )\n",
    "                    \n",
    "        #check diagonal\n",
    "        for i in range( self.R-3 ):\n",
    "            for j in range( self.C-3 ):\n",
    "                if self.board[i][j] != 0:\n",
    "                    x, y = i, j\n",
    "                    a = []\n",
    "                    for k in range(4):\n",
    "                        a.append( self.board[x][y] )\n",
    "                        x += 1\n",
    "                        y += 1\n",
    "                    if same( np.array(a) ):\n",
    "                        return ( a[0] )\n",
    "                    \n",
    "        #check diagonal\n",
    "        for i in range( self.R-3 ):\n",
    "            for j in range( self.C-3 ):\n",
    "                if self.board[i][j] != 0:\n",
    "                    x, y = i, j\n",
    "                    a = []\n",
    "                    for k in range(4):\n",
    "                        a.append( self.board[x][y] )\n",
    "                        x -= 1\n",
    "                        y -= 1\n",
    "                    if same( np.array(a) ):\n",
    "                        return ( a[0] )\n",
    "                    \n",
    "        for i in range( self.R ):\n",
    "            for j in range( self.C ):\n",
    "                if self.board[i][j] == 0:\n",
    "                    return ( False )\n",
    "                    \n",
    "        return ( True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "[np.uint8(0), np.uint8(0), np.uint8(0), np.uint8(0)]\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "env.board\n",
    "env.board[1][1]\n",
    "x, y = 1,1#, j\n",
    "a = []\n",
    "for k in range(4):\n",
    "\n",
    "    print(x,y)\n",
    "    a.append( env.board[x][y] )\n",
    "    x += 1\n",
    "    y += 1\n",
    "    \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 233\u001b[0m\n\u001b[0;32m    231\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\u001b[38;5;66;03m#env.action_space.n\u001b[39;00m\n\u001b[0;32m    232\u001b[0m sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m]\n\u001b[1;32m--> 233\u001b[0m model \u001b[38;5;241m=\u001b[39m DQN(D, K, sizes, gamma)\n\u001b[0;32m    234\u001b[0m tmodel \u001b[38;5;241m=\u001b[39m DQN(D, K, sizes, gamma)\n\u001b[0;32m    235\u001b[0m init \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mglobal_variables_initializer()\n",
      "Cell \u001b[1;32mIn[20], line 42\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[1;34m(self, D, K, hidden_layer_sizes, gamma, max_experiences, min_experiences, batch_sz)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# inputs and targets\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, D), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mint32, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "#begin DQN\n",
    "class HiddenLayer:\n",
    "    def __init__(self, M1, M2, f=tf.nn.tanh, use_bias=True):\n",
    "        self.W = tf.Variable(tf.random_normal(shape=(M1, M2)))\n",
    "        self.params = [self.W]\n",
    "        self.use_bias = use_bias\n",
    "        if use_bias:\n",
    "            self.b = tf.Variable(np.zeros(M2).astype(np.float32))\n",
    "            self.params.append(self.b)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.use_bias:\n",
    "            a = tf.matmul(X, self.W) + self.b\n",
    "        else:\n",
    "            a = tf.matmul(X, self.W)\n",
    "        return self.f(a)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, D, K, hidden_layer_sizes, gamma, max_experiences=100000, min_experiences=2000, batch_sz=32):\n",
    "        self.K = K\n",
    "\n",
    "        # create the graph\n",
    "        self.layers = []\n",
    "        M1 = D\n",
    "        for M2 in hidden_layer_sizes:\n",
    "            layer = HiddenLayer(M1, M2)\n",
    "            self.layers.append(layer)\n",
    "            M1 = M2\n",
    "\n",
    "        # final layer\n",
    "        layer = HiddenLayer(M1, K, lambda x: x)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "        # collect params for copy\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "\n",
    "        # inputs and targets\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "        self.G = tf.placeholder(tf.float32, shape=(None,), name='G')\n",
    "        self.actions = tf.placeholder(tf.int32, shape=(None,), name='actions')\n",
    "\n",
    "        # calculate output and cost\n",
    "        Z = self.X\n",
    "        #Z = tf.contrib.layers.flatten(self.X)\n",
    "        for layer in self.layers:\n",
    "            Z = layer.forward(Z)\n",
    "        Y_hat = Z\n",
    "        self.predict_op = Y_hat\n",
    "\n",
    "        selected_action_values = tf.reduce_sum(\n",
    "          Y_hat * tf.one_hot(self.actions, K),\n",
    "          reduction_indices=[1]\n",
    "        )\n",
    "\n",
    "        cost = tf.reduce_sum(tf.square(self.G - selected_action_values))\n",
    "        self.train_op = tf.train.AdamOptimizer(1e-2).minimize(cost)\n",
    "        # self.train_op = tf.train.AdagradOptimizer(1e-2).minimize(cost)\n",
    "        # self.train_op = tf.train.MomentumOptimizer(1e-3, momentum=0.9).minimize(cost)\n",
    "        # self.train_op = tf.train.GradientDescentOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "        # create replay memory\n",
    "        self.experience = {'s': [], 'a': [], 'r': [], 's2': [], 'done': []}\n",
    "        self.max_experiences = max_experiences\n",
    "        self.min_experiences = min_experiences\n",
    "        self.batch_sz = batch_sz\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "\n",
    "    def copy_from(self, other):\n",
    "        # collect all the ops\n",
    "        ops = []\n",
    "        my_params = self.params\n",
    "        other_params = other.params\n",
    "        for p, q in zip(my_params, other_params):\n",
    "            actual = self.session.run(q)\n",
    "            op = p.assign(actual)\n",
    "            ops.append(op)\n",
    "        # now run them all\n",
    "        self.session.run(ops)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        return self.session.run(self.predict_op, feed_dict={self.X: X})\n",
    "\n",
    "    def train(self, target_network):\n",
    "        # sample a random batch from buffer, do an iteration of GD\n",
    "        if len(self.experience['s']) < self.min_experiences:\n",
    "            # don't do anything if we don't have enough experience\n",
    "            return\n",
    "\n",
    "        # randomly select a batch\n",
    "        idx = np.random.choice(len(self.experience['s']), size=self.batch_sz, replace=False)\n",
    "        # print(\"idx:\", idx)\n",
    "        states = [self.experience['s'][i] for i in idx]\n",
    "        actions = [self.experience['a'][i] for i in idx]\n",
    "        rewards = [self.experience['r'][i] for i in idx]\n",
    "        next_states = [self.experience['s2'][i] for i in idx]\n",
    "        dones = [self.experience['done'][i] for i in idx]\n",
    "        next_Q = np.max(target_network.predict(next_states), axis=1)\n",
    "        targets = [r + self.gamma*next_q if not done else r for r, next_q, done in zip(rewards, next_Q, dones)]\n",
    "\n",
    "        # call optimizer\n",
    "        self.session.run(\n",
    "          self.train_op,\n",
    "          feed_dict={\n",
    "            self.X: states,\n",
    "            self.G: targets,\n",
    "            self.actions: actions\n",
    "          }\n",
    "        )\n",
    "\n",
    "    def add_experience(self, s, a, r, s2, done):\n",
    "        if len(self.experience['s']) >= self.max_experiences:\n",
    "            self.experience['s'].pop(0)\n",
    "            self.experience['a'].pop(0)\n",
    "            self.experience['r'].pop(0)\n",
    "            self.experience['s2'].pop(0)\n",
    "            self.experience['done'].pop(0)\n",
    "            self.experience['s'].append(s)\n",
    "            self.experience['a'].append(a)\n",
    "            self.experience['r'].append(r)\n",
    "            self.experience['s2'].append(s2)\n",
    "            self.experience['done'].append(done)\n",
    "\n",
    "    def sample_action(self, x, eps):\n",
    "        if np.random.random() < eps:\n",
    "            return np.random.choice(self.K)\n",
    "        else:\n",
    "            X = np.atleast_2d(x)\n",
    "        return np.argmax(self.predict(X)[0])\n",
    "\n",
    "#end dqn\n",
    "def play_one(env, model, tmodel, eps, gamma, copy_period, learn=True):\n",
    "  \n",
    "\n",
    "    global iters\n",
    "    env.reset()\n",
    "\n",
    "    observation = env.board.copy().flatten()\n",
    "    prev_observation = observation.copy().flatten()\n",
    "        \n",
    "    done = False\n",
    "\n",
    "    totalreward = 0\n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        reward = 0\n",
    "        \n",
    "        while True:\n",
    "            #until a valid action is given\n",
    "            #action = int( input('Player 1 input') )\n",
    "            \n",
    "            action = model.sample_action(observation, eps)\n",
    "            \n",
    "            placed = env.step(who=1, action=action)\n",
    "            if placed == True:\n",
    "                break\n",
    "\n",
    "        #move has been done, environment has moved to next state, so update\n",
    "        prev_observation = observation.copy().flatten()\n",
    "        observation = env.board.copy().flatten()\n",
    "                \n",
    "        if env.isFinal() > 0:\n",
    "            done = True\n",
    "            reward = +1\n",
    "            # update the model\n",
    "            \n",
    "            model.add_experience(prev_observation, action, reward, observation, done)\n",
    "            model.train(tmodel)\n",
    "            iters += 1\n",
    "            if iters % copy_period == 0:\n",
    "                tmodel.copy_from(model)\n",
    "            break\n",
    "\n",
    "        #print(env.board)\n",
    "\n",
    "        while True:\n",
    "            #until a valid action is given\n",
    "            #action = int( input('Player 2 input') )\n",
    "            \n",
    "            #agent 2 has to take an action based on the \"reversed state\"\n",
    "            #reversed state: every 1 becomes 2 and vice versa\n",
    "            action = model.sample_action( rev(observation), eps)\n",
    "            \n",
    "            placed = env.step(who=2, action=action)\n",
    "            if placed == True:\n",
    "                break\n",
    "\n",
    "        #move has been done, environment has moved to next state, so update\n",
    "        prev_observation = observation.copy().flatten()\n",
    "        observation = env.board.copy().flatten()\n",
    "        \n",
    "        if env.isFinal() > 0:\n",
    "            done = True\n",
    "            reward = -1\n",
    "            # update the model\n",
    "            \n",
    "            if learn:\n",
    "                model.add_experience(prev_observation, action, reward, observation, done)\n",
    "                model.train(tmodel)\n",
    "                iters += 1\n",
    "                if iters % copy_period == 0:\n",
    "                    tmodel.copy_from(model)\n",
    "            break\n",
    "\n",
    "        #print(env.board)\n",
    "        \n",
    "        observation = env.board.copy().flatten()\n",
    "        \n",
    "        # update the model\n",
    "        if learn:\n",
    "            model.add_experience(prev_observation, action, reward, observation, done)\n",
    "            model.train(tmodel)\n",
    "            iters += 1\n",
    "            if iters % copy_period == 0:\n",
    "                tmodel.copy_from(model)\n",
    "\n",
    "        \n",
    "    return reward\n",
    "gamma = 0.99\n",
    "copy_period = 50\n",
    "\n",
    "D = 6*7#len(env.observation_space.sample())\n",
    "K = 7#env.action_space.n\n",
    "sizes = [512,256,128,64,64]\n",
    "model = DQN(D, K, sizes, gamma)\n",
    "tmodel = DQN(D, K, sizes, gamma)\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.InteractiveSession()\n",
    "session.run(init)\n",
    "model.set_session(session)\n",
    "tmodel.set_session(session)\n",
    "\n",
    "\n",
    "iters = 1\n",
    "\n",
    "N = 1500\n",
    "totalrewards = np.empty(N)\n",
    "costs = np.empty(N)\n",
    "avg = []\n",
    "\n",
    "begin = time.time()\n",
    "\n",
    "for n in range(N):\n",
    "    eps = 0.1#1.0/np.sqrt(n+1)\n",
    "    totalreward = play_one(env, model, tmodel, eps, gamma, copy_period)\n",
    "    totalrewards[n] = totalreward\n",
    "    #if n % 100 == 0:\n",
    "    mean_reward = totalrewards[max(0, n-100):(n+1)].mean()\n",
    "    avg.append( mean_reward )\n",
    "    print(\"episode:\", n, \"total reward:\", totalreward, \"eps:\", eps, \"avg reward (last 100):\", mean_reward )\n",
    "\n",
    "    #print( env.board)\n",
    "    \n",
    "print(\"avg reward for last 100 episodes:\", totalrewards[-100:].mean())\n",
    "print(\"total steps:\", totalrewards.sum())\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print( end - begin )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
