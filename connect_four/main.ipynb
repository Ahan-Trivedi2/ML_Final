{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\users\\nsingh\\appdata\\local\\anaconda3\\lib\\site-packages (from scipy) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy<2\n",
    "!pip install --upgrade scipy\n",
    "!pip install pybind11>=2.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import tkinter\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image\n",
    "\n",
    "root = tkinter.Tk()\n",
    "#Setting it up\n",
    "keno = ImageTk.PhotoImage(Image.open(\"./keno.png\"))\n",
    "red = ImageTk.PhotoImage(Image.open(\"./kokkino.png\"))\n",
    "blue = ImageTk.PhotoImage(Image.open(\"./ble.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same(a):\n",
    "    \n",
    "    for i in range( len(a) ):\n",
    "        if a[0] != a[i]:\n",
    "            return ( False )\n",
    "        \n",
    "    return ( True )\n",
    "\n",
    "#reverse state for 2nd agent, so that it can make predictions according to what the 1st agent has learned so far\n",
    "def rev( a ):\n",
    "    b = a.copy()\n",
    "    b[ a == 1 ] = 2\n",
    "    b[ a == 2 ] = 1\n",
    "    return ( b.copy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.R, self.C = 6,7\n",
    "        self.board = np.zeros( (self.R,self.C), dtype='uint8' )\n",
    "    \n",
    "    def reset(self):\n",
    "        for i in range( self.R ):\n",
    "            for j in range( self.C ):\n",
    "                self.board[i][j] = 0\n",
    "    \n",
    "    def step(self,who,action):\n",
    "        \n",
    "        placed = False\n",
    "        for j in range( self.R-1, -1, -1 ):\n",
    "            if self.board[j][action] == 0:\n",
    "                self.board[j][action] = who\n",
    "                placed = True\n",
    "                break\n",
    "        \n",
    "        return ( placed )\n",
    "    \n",
    "    def getState(self):\n",
    "        return self.board.copy()\n",
    "    \n",
    "    def isFinal(self):\n",
    "        \n",
    "        #check horizontal\n",
    "        for i in range( self.R ):\n",
    "            for j in range( self.C ):\n",
    "                if self.board[i][j] != 0:\n",
    "                    x, y = i, j\n",
    "                    a = []\n",
    "                    for k in range(4):\n",
    "                        a.append( self.board[x][y] )\n",
    "                        y += 1\n",
    "                        if y >= self.C:\n",
    "                            break\n",
    "                    if same( np.array(a) ) and len(a) == 4:\n",
    "                        return ( a[0] )\n",
    "                \n",
    "        #check vertical\n",
    "        for i in range( self.R ):\n",
    "            for j in range( self.C ):\n",
    "                if self.board[i][j] != 0:\n",
    "                    x, y = i, j\n",
    "                    a = []\n",
    "                    for k in range(4):\n",
    "                        a.append( self.board[x][y] )\n",
    "                        x += 1\n",
    "                        if x >= self.R:\n",
    "                            break\n",
    "                    if same( np.array(a) ) and len(a) == 4:\n",
    "                        return ( a[0] )\n",
    "                    \n",
    "        #check diagonal\n",
    "        for i in range( self.R-3 ):\n",
    "            for j in range( self.C-3 ):\n",
    "                if self.board[i][j] != 0:\n",
    "                    x, y = i, j\n",
    "                    a = []\n",
    "                    for k in range(4):\n",
    "                        a.append( self.board[x][y] )\n",
    "                        x += 1\n",
    "                        y += 1\n",
    "                    if same( np.array(a) ):\n",
    "                        return ( a[0] )\n",
    "                    \n",
    "        #check diagonal\n",
    "        for i in range( self.R-3 ):\n",
    "            for j in range( self.C-3 ):\n",
    "                if self.board[i][j] != 0:\n",
    "                    x, y = i, j\n",
    "                    a = []\n",
    "                    for k in range(4):\n",
    "                        a.append( self.board[x][y] )\n",
    "                        x -= 1\n",
    "                        y -= 1\n",
    "                    if same( np.array(a) ):\n",
    "                        return ( a[0] )\n",
    "                    \n",
    "        for i in range( self.R ):\n",
    "            for j in range( self.C ):\n",
    "                if self.board[i][j] == 0:\n",
    "                    return ( False )\n",
    "                    \n",
    "        return ( True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "[np.uint8(0), np.uint8(0), np.uint8(0), np.uint8(0)]\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "env.board\n",
    "env.board[1][1]\n",
    "x, y = 1,1#, j\n",
    "a = []\n",
    "for k in range(4):\n",
    "\n",
    "    print(x,y)\n",
    "    a.append( env.board[x][y] )\n",
    "    x += 1\n",
    "    y += 1\n",
    "    \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:An interactive session is already active. This can cause out-of-memory errors or some other unexpected errors (due to the unpredictable timing of garbage collection) in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s). Please use `tf.Session()` if you intend to productionize.\n",
      "episode: 0 total reward: -1 eps: 0.1 avg reward (last 100): -1.0\n",
      "episode: 1 total reward: -1 eps: 0.1 avg reward (last 100): -1.0\n",
      "episode: 2 total reward: 1 eps: 0.1 avg reward (last 100): -0.3333333333333333\n",
      "episode: 3 total reward: -1 eps: 0.1 avg reward (last 100): -0.5\n",
      "episode: 4 total reward: -1 eps: 0.1 avg reward (last 100): -0.6\n",
      "episode: 5 total reward: -1 eps: 0.1 avg reward (last 100): -0.6666666666666666\n",
      "episode: 6 total reward: -1 eps: 0.1 avg reward (last 100): -0.7142857142857143\n",
      "episode: 7 total reward: 1 eps: 0.1 avg reward (last 100): -0.5\n",
      "episode: 8 total reward: -1 eps: 0.1 avg reward (last 100): -0.5555555555555556\n",
      "episode: 9 total reward: 1 eps: 0.1 avg reward (last 100): -0.4\n",
      "episode: 10 total reward: -1 eps: 0.1 avg reward (last 100): -0.45454545454545453\n",
      "episode: 11 total reward: -1 eps: 0.1 avg reward (last 100): -0.5\n",
      "episode: 12 total reward: 1 eps: 0.1 avg reward (last 100): -0.38461538461538464\n",
      "episode: 13 total reward: -1 eps: 0.1 avg reward (last 100): -0.42857142857142855\n",
      "episode: 14 total reward: -1 eps: 0.1 avg reward (last 100): -0.4666666666666667\n",
      "episode: 15 total reward: 1 eps: 0.1 avg reward (last 100): -0.375\n",
      "episode: 16 total reward: 1 eps: 0.1 avg reward (last 100): -0.29411764705882354\n",
      "episode: 17 total reward: 1 eps: 0.1 avg reward (last 100): -0.2222222222222222\n",
      "episode: 18 total reward: 1 eps: 0.1 avg reward (last 100): -0.15789473684210525\n",
      "episode: 19 total reward: 1 eps: 0.1 avg reward (last 100): -0.1\n",
      "episode: 20 total reward: -1 eps: 0.1 avg reward (last 100): -0.14285714285714285\n",
      "episode: 21 total reward: -1 eps: 0.1 avg reward (last 100): -0.18181818181818182\n",
      "episode: 22 total reward: -1 eps: 0.1 avg reward (last 100): -0.21739130434782608\n",
      "episode: 23 total reward: -1 eps: 0.1 avg reward (last 100): -0.25\n",
      "episode: 24 total reward: -1 eps: 0.1 avg reward (last 100): -0.28\n",
      "episode: 25 total reward: 1 eps: 0.1 avg reward (last 100): -0.23076923076923078\n",
      "episode: 26 total reward: -1 eps: 0.1 avg reward (last 100): -0.25925925925925924\n",
      "episode: 27 total reward: -1 eps: 0.1 avg reward (last 100): -0.2857142857142857\n",
      "episode: 28 total reward: -1 eps: 0.1 avg reward (last 100): -0.3103448275862069\n",
      "episode: 29 total reward: 1 eps: 0.1 avg reward (last 100): -0.26666666666666666\n",
      "episode: 30 total reward: 1 eps: 0.1 avg reward (last 100): -0.22580645161290322\n",
      "episode: 31 total reward: 1 eps: 0.1 avg reward (last 100): -0.1875\n",
      "episode: 32 total reward: 1 eps: 0.1 avg reward (last 100): -0.15151515151515152\n",
      "episode: 33 total reward: -1 eps: 0.1 avg reward (last 100): -0.17647058823529413\n",
      "episode: 34 total reward: 1 eps: 0.1 avg reward (last 100): -0.14285714285714285\n",
      "episode: 35 total reward: 1 eps: 0.1 avg reward (last 100): -0.1111111111111111\n",
      "episode: 36 total reward: 1 eps: 0.1 avg reward (last 100): -0.08108108108108109\n",
      "episode: 37 total reward: 1 eps: 0.1 avg reward (last 100): -0.05263157894736842\n",
      "episode: 38 total reward: -1 eps: 0.1 avg reward (last 100): -0.07692307692307693\n",
      "episode: 39 total reward: -1 eps: 0.1 avg reward (last 100): -0.1\n",
      "episode: 40 total reward: 1 eps: 0.1 avg reward (last 100): -0.07317073170731707\n",
      "episode: 41 total reward: -1 eps: 0.1 avg reward (last 100): -0.09523809523809523\n",
      "episode: 42 total reward: -1 eps: 0.1 avg reward (last 100): -0.11627906976744186\n",
      "episode: 43 total reward: -1 eps: 0.1 avg reward (last 100): -0.13636363636363635\n",
      "episode: 44 total reward: 1 eps: 0.1 avg reward (last 100): -0.1111111111111111\n",
      "episode: 45 total reward: 1 eps: 0.1 avg reward (last 100): -0.08695652173913043\n",
      "episode: 46 total reward: -1 eps: 0.1 avg reward (last 100): -0.10638297872340426\n",
      "episode: 47 total reward: -1 eps: 0.1 avg reward (last 100): -0.125\n",
      "episode: 48 total reward: 1 eps: 0.1 avg reward (last 100): -0.10204081632653061\n",
      "episode: 49 total reward: 1 eps: 0.1 avg reward (last 100): -0.08\n",
      "episode: 50 total reward: -1 eps: 0.1 avg reward (last 100): -0.09803921568627451\n",
      "episode: 51 total reward: 1 eps: 0.1 avg reward (last 100): -0.07692307692307693\n",
      "episode: 52 total reward: -1 eps: 0.1 avg reward (last 100): -0.09433962264150944\n",
      "episode: 53 total reward: -1 eps: 0.1 avg reward (last 100): -0.1111111111111111\n",
      "episode: 54 total reward: -1 eps: 0.1 avg reward (last 100): -0.12727272727272726\n",
      "episode: 55 total reward: 1 eps: 0.1 avg reward (last 100): -0.10714285714285714\n",
      "episode: 56 total reward: -1 eps: 0.1 avg reward (last 100): -0.12280701754385964\n",
      "episode: 57 total reward: 1 eps: 0.1 avg reward (last 100): -0.10344827586206896\n",
      "episode: 58 total reward: 1 eps: 0.1 avg reward (last 100): -0.0847457627118644\n",
      "episode: 59 total reward: -1 eps: 0.1 avg reward (last 100): -0.1\n",
      "episode: 60 total reward: 1 eps: 0.1 avg reward (last 100): -0.08196721311475409\n",
      "episode: 61 total reward: 1 eps: 0.1 avg reward (last 100): -0.06451612903225806\n",
      "episode: 62 total reward: 1 eps: 0.1 avg reward (last 100): -0.047619047619047616\n",
      "episode: 63 total reward: 1 eps: 0.1 avg reward (last 100): -0.03125\n",
      "episode: 64 total reward: 1 eps: 0.1 avg reward (last 100): -0.015384615384615385\n",
      "episode: 65 total reward: 1 eps: 0.1 avg reward (last 100): 0.0\n",
      "episode: 66 total reward: -1 eps: 0.1 avg reward (last 100): -0.014925373134328358\n",
      "episode: 67 total reward: 1 eps: 0.1 avg reward (last 100): 0.0\n",
      "episode: 68 total reward: 1 eps: 0.1 avg reward (last 100): 0.014492753623188406\n",
      "episode: 69 total reward: 1 eps: 0.1 avg reward (last 100): 0.02857142857142857\n",
      "episode: 70 total reward: 1 eps: 0.1 avg reward (last 100): 0.04225352112676056\n",
      "episode: 71 total reward: -1 eps: 0.1 avg reward (last 100): 0.027777777777777776\n",
      "episode: 72 total reward: -1 eps: 0.1 avg reward (last 100): 0.0136986301369863\n",
      "episode: 73 total reward: -1 eps: 0.1 avg reward (last 100): 0.0\n",
      "episode: 74 total reward: -1 eps: 0.1 avg reward (last 100): -0.013333333333333334\n",
      "episode: 75 total reward: 1 eps: 0.1 avg reward (last 100): 0.0\n",
      "episode: 76 total reward: 1 eps: 0.1 avg reward (last 100): 0.012987012987012988\n",
      "episode: 77 total reward: 1 eps: 0.1 avg reward (last 100): 0.02564102564102564\n",
      "episode: 78 total reward: -1 eps: 0.1 avg reward (last 100): 0.012658227848101266\n",
      "episode: 79 total reward: -1 eps: 0.1 avg reward (last 100): 0.0\n",
      "episode: 80 total reward: 1 eps: 0.1 avg reward (last 100): 0.012345679012345678\n",
      "episode: 81 total reward: 1 eps: 0.1 avg reward (last 100): 0.024390243902439025\n",
      "episode: 82 total reward: -1 eps: 0.1 avg reward (last 100): 0.012048192771084338\n",
      "episode: 83 total reward: -1 eps: 0.1 avg reward (last 100): 0.0\n",
      "episode: 84 total reward: -1 eps: 0.1 avg reward (last 100): -0.011764705882352941\n",
      "episode: 85 total reward: -1 eps: 0.1 avg reward (last 100): -0.023255813953488372\n",
      "episode: 86 total reward: 1 eps: 0.1 avg reward (last 100): -0.011494252873563218\n",
      "episode: 87 total reward: 1 eps: 0.1 avg reward (last 100): 0.0\n",
      "episode: 88 total reward: 1 eps: 0.1 avg reward (last 100): 0.011235955056179775\n",
      "episode: 89 total reward: 1 eps: 0.1 avg reward (last 100): 0.022222222222222223\n",
      "episode: 90 total reward: 1 eps: 0.1 avg reward (last 100): 0.03296703296703297\n",
      "episode: 91 total reward: 1 eps: 0.1 avg reward (last 100): 0.043478260869565216\n",
      "episode: 92 total reward: 1 eps: 0.1 avg reward (last 100): 0.053763440860215055\n",
      "episode: 93 total reward: 1 eps: 0.1 avg reward (last 100): 0.06382978723404255\n",
      "episode: 94 total reward: 1 eps: 0.1 avg reward (last 100): 0.07368421052631578\n",
      "episode: 95 total reward: 1 eps: 0.1 avg reward (last 100): 0.08333333333333333\n",
      "episode: 96 total reward: 1 eps: 0.1 avg reward (last 100): 0.09278350515463918\n",
      "episode: 97 total reward: -1 eps: 0.1 avg reward (last 100): 0.08163265306122448\n",
      "episode: 98 total reward: -1 eps: 0.1 avg reward (last 100): 0.0707070707070707\n",
      "episode: 99 total reward: 1 eps: 0.1 avg reward (last 100): 0.08\n",
      "episode: 100 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 101 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 102 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 103 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 104 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 105 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 106 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 107 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 108 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 109 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 110 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 111 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 112 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 113 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 114 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 115 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 116 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 117 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 118 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 119 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 120 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 121 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 122 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 123 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 124 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 125 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 126 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 127 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 128 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 129 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 130 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 131 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 132 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 133 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 134 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 135 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 136 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 137 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 138 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 139 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 140 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 141 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 142 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 143 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 144 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 145 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 146 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 147 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 148 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 149 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 150 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 151 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 152 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 153 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 154 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 155 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 156 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 157 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 158 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 159 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 160 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 161 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 162 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 163 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 164 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 165 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 166 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 167 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 168 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 169 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 170 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 171 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 172 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 173 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 174 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 175 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 176 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 177 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 178 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 179 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 180 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 181 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 182 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 183 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 184 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 185 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 186 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 187 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 188 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 189 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 190 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 191 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 192 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 193 total reward: -1 eps: 0.1 avg reward (last 100): -0.0297029702970297\n",
      "episode: 194 total reward: -1 eps: 0.1 avg reward (last 100): -0.04950495049504951\n",
      "episode: 195 total reward: 1 eps: 0.1 avg reward (last 100): -0.04950495049504951\n",
      "episode: 196 total reward: -1 eps: 0.1 avg reward (last 100): -0.06930693069306931\n",
      "episode: 197 total reward: -1 eps: 0.1 avg reward (last 100): -0.0891089108910891\n",
      "episode: 198 total reward: 1 eps: 0.1 avg reward (last 100): -0.06930693069306931\n",
      "episode: 199 total reward: 1 eps: 0.1 avg reward (last 100): -0.04950495049504951\n",
      "episode: 200 total reward: 1 eps: 0.1 avg reward (last 100): -0.04950495049504951\n",
      "episode: 201 total reward: -1 eps: 0.1 avg reward (last 100): -0.06930693069306931\n",
      "episode: 202 total reward: 1 eps: 0.1 avg reward (last 100): -0.04950495049504951\n",
      "episode: 203 total reward: 1 eps: 0.1 avg reward (last 100): -0.04950495049504951\n",
      "episode: 204 total reward: -1 eps: 0.1 avg reward (last 100): -0.04950495049504951\n",
      "episode: 205 total reward: 1 eps: 0.1 avg reward (last 100): -0.0297029702970297\n",
      "episode: 206 total reward: -1 eps: 0.1 avg reward (last 100): -0.0297029702970297\n",
      "episode: 207 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 208 total reward: -1 eps: 0.1 avg reward (last 100): -0.0297029702970297\n",
      "episode: 209 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 210 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 211 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 212 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 213 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 214 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 215 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 216 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 217 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 218 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 219 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 220 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 221 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 222 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 223 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 224 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 225 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 226 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 227 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 228 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 229 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 230 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 231 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 232 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 233 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 234 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 235 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 236 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 237 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 238 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 239 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 240 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 241 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 242 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 243 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 244 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 245 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 246 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 247 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 248 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 249 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 250 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 251 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 252 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 253 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 254 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 255 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 256 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 257 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 258 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 259 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 260 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 261 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 262 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 263 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 264 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 265 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 266 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 267 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 268 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 269 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 270 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 271 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 272 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 273 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 274 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 275 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 276 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 277 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 278 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 279 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 280 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 281 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 282 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 283 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 284 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 285 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 286 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 287 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 288 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 289 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 290 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 291 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 292 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 293 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 294 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 295 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 296 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 297 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 298 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 299 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 300 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 301 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 302 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 303 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 304 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 305 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 306 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 307 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 308 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 309 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 310 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 311 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 312 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 313 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 314 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 315 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 316 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 317 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 318 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 319 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 320 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 321 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 322 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 323 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 324 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 325 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 326 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 327 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 328 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 329 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 330 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 331 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 332 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 333 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 334 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 335 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 336 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 337 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 338 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 339 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 340 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 341 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 342 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 343 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 344 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 345 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 346 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 347 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 348 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 349 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 350 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 351 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 352 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 353 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 354 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 355 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 356 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 357 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 358 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 359 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 360 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 361 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 362 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 363 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 364 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 365 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 366 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 367 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 368 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 369 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 370 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 371 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 372 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 373 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 374 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 375 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 376 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 377 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 378 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 379 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 380 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 381 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 382 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 383 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 384 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 385 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 386 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 387 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 388 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 389 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 390 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 391 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 392 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 393 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 394 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 395 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 396 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 397 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 398 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 399 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 400 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 401 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 402 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 403 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 404 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 405 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 406 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 407 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 408 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 409 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 410 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 411 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 412 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 413 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 414 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 415 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 416 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 417 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 418 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 419 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 420 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 421 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 422 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 423 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 424 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 425 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 426 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 427 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 428 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 429 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 430 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 431 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 432 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 433 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 434 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 435 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 436 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 437 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 438 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 439 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 440 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 441 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 442 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 443 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 444 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 445 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 446 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 447 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 448 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 449 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 450 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 451 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 452 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 453 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 454 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 455 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 456 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 457 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 458 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 459 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 460 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 461 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 462 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 463 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 464 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 465 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 466 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 467 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 468 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 469 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 470 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 471 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 472 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 473 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 474 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 475 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 476 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 477 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 478 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 479 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 480 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 481 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 482 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 483 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 484 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 485 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 486 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 487 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 488 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 489 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 490 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 491 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 492 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 493 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 494 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 495 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 496 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 497 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 498 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 499 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 500 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 501 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 502 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 503 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 504 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 505 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 506 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 507 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 508 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 509 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 510 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 511 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 512 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 513 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 514 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 515 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 516 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 517 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 518 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 519 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 520 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 521 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 522 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 523 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 524 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 525 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 526 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 527 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 528 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 529 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 530 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 531 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 532 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 533 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 534 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 535 total reward: -1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 536 total reward: 1 eps: 0.1 avg reward (last 100): -0.009900990099009901\n",
      "episode: 537 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 538 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 539 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 540 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 541 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 542 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 543 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 544 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 545 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 546 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 547 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 548 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 549 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 550 total reward: 1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 551 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 552 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 553 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 554 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 555 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 556 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 557 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 558 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 559 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 560 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 561 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 562 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 563 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 564 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 565 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 566 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 567 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 568 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 569 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 570 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 571 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 572 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 573 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 574 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 575 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 576 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 577 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 578 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 579 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 580 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 581 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 582 total reward: -1 eps: 0.1 avg reward (last 100): 0.009900990099009901\n",
      "episode: 583 total reward: 1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 584 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 585 total reward: -1 eps: 0.1 avg reward (last 100): 0.0297029702970297\n",
      "episode: 586 total reward: 1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 587 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 588 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 589 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 590 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 591 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 592 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 593 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 594 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 595 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 596 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 597 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 598 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 599 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 600 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 601 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 602 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 603 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 604 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 605 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 606 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 607 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 608 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 609 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 610 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 611 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 612 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 613 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 614 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 615 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 616 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 617 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 618 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 619 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 620 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 621 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 622 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 623 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 624 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 625 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 626 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 627 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 628 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 629 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 630 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 631 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 632 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 633 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 634 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 635 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 636 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 637 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 638 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 639 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 640 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 641 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 642 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 643 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 644 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 645 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 646 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 647 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 648 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 649 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 650 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 651 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 652 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 653 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 654 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 655 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 656 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 657 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 658 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 659 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 660 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 661 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 662 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 663 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 664 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 665 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 666 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 667 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 668 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 669 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 670 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 671 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 672 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 673 total reward: -1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 674 total reward: -1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 675 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 676 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 677 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 678 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 679 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 680 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 681 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 682 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 683 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 684 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 685 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 686 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 687 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 688 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 689 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 690 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 691 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 692 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 693 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 694 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 695 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 696 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 697 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 698 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 699 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 700 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 701 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 702 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 703 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 704 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 705 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 706 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 707 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 708 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 709 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 710 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 711 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 712 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 713 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 714 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 715 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 716 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 717 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 718 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 719 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 720 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 721 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 722 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 723 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 724 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 725 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 726 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 727 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 728 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 729 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 730 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 731 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 732 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 733 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 734 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 735 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 736 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 737 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 738 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 739 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 740 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 741 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 742 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 743 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 744 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 745 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 746 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 747 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 748 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 749 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 750 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 751 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 752 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 753 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 754 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 755 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 756 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 757 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 758 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 759 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 760 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 761 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 762 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 763 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 764 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 765 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 766 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 767 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 768 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 769 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 770 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 771 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 772 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 773 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 774 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 775 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 776 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 777 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 778 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 779 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 780 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 781 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 782 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 783 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 784 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 785 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 786 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 787 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 788 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 789 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 790 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 791 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 792 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 793 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 794 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 795 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 796 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 797 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 798 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 799 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 800 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 801 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 802 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 803 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 804 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 805 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 806 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 807 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 808 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 809 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 810 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 811 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 812 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 813 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 814 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 815 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 816 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 817 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 818 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 819 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 820 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 821 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 822 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 823 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 824 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 825 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 826 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 827 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 828 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 829 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 830 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 831 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 832 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 833 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 834 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 835 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 836 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 837 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 838 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 839 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 840 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 841 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 842 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 843 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 844 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 845 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 846 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 847 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 848 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 849 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 850 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 851 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 852 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 853 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 854 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 855 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 856 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 857 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 858 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 859 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 860 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 861 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 862 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 863 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 864 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 865 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 866 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 867 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 868 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 869 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 870 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 871 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 872 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 873 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 874 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 875 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 876 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 877 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 878 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 879 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 880 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 881 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 882 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 883 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 884 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 885 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 886 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 887 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 888 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 889 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 890 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 891 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 892 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 893 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 894 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 895 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 896 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 897 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 898 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 899 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 900 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 901 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 902 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 903 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 904 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 905 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 906 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 907 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 908 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 909 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 910 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 911 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 912 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 913 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 914 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 915 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 916 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 917 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 918 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 919 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 920 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 921 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 922 total reward: -1 eps: 0.1 avg reward (last 100): 0.04950495049504951\n",
      "episode: 923 total reward: 1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 924 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 925 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 926 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 927 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 928 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 929 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 930 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 931 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 932 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 933 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 934 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 935 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 936 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 937 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 938 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 939 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 940 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 941 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 942 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 943 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 944 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 945 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 946 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 947 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 948 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 949 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 950 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 951 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 952 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 953 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 954 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 955 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 956 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 957 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 958 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 959 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 960 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 961 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 962 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 963 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 964 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 965 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 966 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 967 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 968 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 969 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 970 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 971 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 972 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 973 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 974 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 975 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 976 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 977 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 978 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 979 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 980 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 981 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 982 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 983 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 984 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 985 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 986 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 987 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 988 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 989 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 990 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 991 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 992 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 993 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 994 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 995 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 996 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 997 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 998 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 999 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1000 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1001 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1002 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1003 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1004 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1005 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1006 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1007 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1008 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1009 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1010 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1011 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1012 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1013 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1014 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1015 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1016 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1017 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1018 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1019 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1020 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1021 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1022 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1023 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1024 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1025 total reward: -1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1026 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1027 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1028 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1029 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1030 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1031 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1032 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1033 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1034 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1035 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1036 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1037 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1038 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1039 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1040 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1041 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1042 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1043 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1044 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1045 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1046 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1047 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1048 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1049 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1050 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1051 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1052 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1053 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1054 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1055 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1056 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1057 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1058 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1059 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1060 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1061 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1062 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1063 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1064 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1065 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1066 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1067 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1068 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1069 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1070 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1071 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1072 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1073 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1074 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1075 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1076 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1077 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1078 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1079 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1080 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1081 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1082 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1083 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1084 total reward: -1 eps: 0.1 avg reward (last 100): 0.06930693069306931\n",
      "episode: 1085 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1086 total reward: 1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1087 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1088 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1089 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1090 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1091 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1092 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1093 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1094 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1095 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1096 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1097 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1098 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1099 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1100 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1101 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1102 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1103 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1104 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1105 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1106 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1107 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1108 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1109 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1110 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1111 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1112 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1113 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1114 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1115 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1116 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1117 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1118 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1119 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1120 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1121 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1122 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1123 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1124 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1125 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1126 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1127 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1128 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1129 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1130 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1131 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1132 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1133 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1134 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1135 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1136 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1137 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1138 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1139 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1140 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1141 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1142 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1143 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1144 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1145 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1146 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1147 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1148 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1149 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1150 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1151 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1152 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1153 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1154 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1155 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1156 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1157 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1158 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1159 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1160 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1161 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1162 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1163 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1164 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1165 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1166 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1167 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1168 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1169 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1170 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1171 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1172 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1173 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1174 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1175 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1176 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1177 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1178 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1179 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1180 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1181 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1182 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1183 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1184 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1185 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1186 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1187 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1188 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1189 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1190 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1191 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1192 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1193 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1194 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1195 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1196 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1197 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1198 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1199 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1200 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1201 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1202 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1203 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1204 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1205 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1206 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1207 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1208 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1209 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1210 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1211 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1212 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1213 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1214 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1215 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1216 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1217 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1218 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1219 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1220 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1221 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1222 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1223 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1224 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1225 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1226 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1227 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1228 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1229 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1230 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1231 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1232 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1233 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1234 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1235 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1236 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1237 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1238 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1239 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1240 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1241 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1242 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1243 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1244 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1245 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1246 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1247 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1248 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1249 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1250 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1251 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1252 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1253 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1254 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1255 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1256 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1257 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1258 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1259 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1260 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1261 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1262 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1263 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1264 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1265 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1266 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1267 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1268 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1269 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1270 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1271 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1272 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1273 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1274 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1275 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1276 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1277 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1278 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1279 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1280 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1281 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1282 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1283 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1284 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1285 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1286 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1287 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1288 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1289 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1290 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1291 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1292 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1293 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1294 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1295 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1296 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1297 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1298 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1299 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1300 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1301 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1302 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1303 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1304 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1305 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1306 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1307 total reward: -1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1308 total reward: -1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1309 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1310 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1311 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1312 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1313 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1314 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1315 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1316 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1317 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1318 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1319 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1320 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1321 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1322 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1323 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1324 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1325 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1326 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1327 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1328 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1329 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1330 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1331 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1332 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1333 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1334 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1335 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1336 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1337 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1338 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1339 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1340 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1341 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1342 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1343 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1344 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1345 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1346 total reward: -1 eps: 0.1 avg reward (last 100): 0.0891089108910891\n",
      "episode: 1347 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1348 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1349 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1350 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1351 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1352 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1353 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1354 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1355 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1356 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1357 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1358 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1359 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1360 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1361 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1362 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1363 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1364 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1365 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1366 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1367 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1368 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1369 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1370 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1371 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1372 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1373 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1374 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1375 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1376 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1377 total reward: 1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1378 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1379 total reward: -1 eps: 0.1 avg reward (last 100): 0.10891089108910891\n",
      "episode: 1380 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1381 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1382 total reward: 1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1383 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1384 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1385 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1386 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1387 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1388 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1389 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1390 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1391 total reward: -1 eps: 0.1 avg reward (last 100): 0.12871287128712872\n",
      "episode: 1392 total reward: 1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1393 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1394 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1395 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1396 total reward: -1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1397 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1398 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1399 total reward: -1 eps: 0.1 avg reward (last 100): 0.1485148514851485\n",
      "episode: 1400 total reward: 1 eps: 0.1 avg reward (last 100): 0.16831683168316833\n",
      "episode: 1401 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1402 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1403 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1404 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1405 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1406 total reward: 1 eps: 0.1 avg reward (last 100): 0.18811881188118812\n",
      "episode: 1407 total reward: 1 eps: 0.1 avg reward (last 100): 0.2079207920792079\n",
      "episode: 1408 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1409 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1410 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1411 total reward: -1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1412 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1413 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1414 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1415 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1416 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1417 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1418 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1419 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1420 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1421 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1422 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1423 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1424 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1425 total reward: -1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1426 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1427 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1428 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1429 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1430 total reward: -1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1431 total reward: -1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1432 total reward: -1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1433 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1434 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1435 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1436 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1437 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1438 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1439 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1440 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1441 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1442 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1443 total reward: 1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1444 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1445 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1446 total reward: -1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1447 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1448 total reward: -1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1449 total reward: 1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1450 total reward: -1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1451 total reward: 1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1452 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1453 total reward: 1 eps: 0.1 avg reward (last 100): 0.36633663366336633\n",
      "episode: 1454 total reward: -1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1455 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1456 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1457 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1458 total reward: -1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1459 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1460 total reward: -1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1461 total reward: 1 eps: 0.1 avg reward (last 100): 0.3465346534653465\n",
      "episode: 1462 total reward: -1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1463 total reward: 1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1464 total reward: -1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1465 total reward: 1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1466 total reward: -1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1467 total reward: -1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1468 total reward: -1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1469 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1470 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1471 total reward: 1 eps: 0.1 avg reward (last 100): 0.32673267326732675\n",
      "episode: 1472 total reward: -1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1473 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1474 total reward: -1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1475 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1476 total reward: -1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1477 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1478 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1479 total reward: -1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1480 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1481 total reward: -1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1482 total reward: -1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1483 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1484 total reward: -1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1485 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1486 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1487 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1488 total reward: -1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1489 total reward: 1 eps: 0.1 avg reward (last 100): 0.22772277227722773\n",
      "episode: 1490 total reward: 1 eps: 0.1 avg reward (last 100): 0.24752475247524752\n",
      "episode: 1491 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1492 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1493 total reward: -1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1494 total reward: 1 eps: 0.1 avg reward (last 100): 0.26732673267326734\n",
      "episode: 1495 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1496 total reward: 1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "episode: 1497 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1498 total reward: 1 eps: 0.1 avg reward (last 100): 0.3069306930693069\n",
      "episode: 1499 total reward: -1 eps: 0.1 avg reward (last 100): 0.2871287128712871\n",
      "avg reward for last 100 episodes: 0.3\n",
      "total steps: 224.0\n",
      "706.7619907855988\n"
     ]
    }
   ],
   "source": [
    "#begin DQN\n",
    "class HiddenLayer:\n",
    "    def __init__(self, M1, M2, f=tf.nn.tanh, use_bias=True):\n",
    "        self.W = tf.Variable(tf.random_normal(shape=(M1, M2)))\n",
    "        self.params = [self.W]\n",
    "        self.use_bias = use_bias\n",
    "        if use_bias:\n",
    "            self.b = tf.Variable(np.zeros(M2).astype(np.float32))\n",
    "            self.params.append(self.b)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.use_bias:\n",
    "            a = tf.matmul(X, self.W) + self.b\n",
    "        else:\n",
    "            a = tf.matmul(X, self.W)\n",
    "        return self.f(a)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, D, K, hidden_layer_sizes, gamma, max_experiences=100000, min_experiences=2000, batch_sz=32):\n",
    "        self.K = K\n",
    "\n",
    "        # create the graph\n",
    "        self.layers = []\n",
    "        M1 = D\n",
    "        for M2 in hidden_layer_sizes:\n",
    "            layer = HiddenLayer(M1, M2)\n",
    "            self.layers.append(layer)\n",
    "            M1 = M2\n",
    "\n",
    "        # final layer\n",
    "        layer = HiddenLayer(M1, K, lambda x: x)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "        # collect params for copy\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "\n",
    "        # inputs and targets\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "        self.G = tf.placeholder(tf.float32, shape=(None,), name='G')\n",
    "        self.actions = tf.placeholder(tf.int32, shape=(None,), name='actions')\n",
    "\n",
    "        # calculate output and cost\n",
    "        Z = self.X\n",
    "        #Z = tf.contrib.layers.flatten(self.X)\n",
    "        for layer in self.layers:\n",
    "            Z = layer.forward(Z)\n",
    "        Y_hat = Z\n",
    "        self.predict_op = Y_hat\n",
    "\n",
    "        selected_action_values = tf.reduce_sum(\n",
    "          Y_hat * tf.one_hot(self.actions, K),\n",
    "          reduction_indices=[1]\n",
    "        )\n",
    "\n",
    "        cost = tf.reduce_sum(tf.square(self.G - selected_action_values))\n",
    "        self.train_op = tf.train.AdamOptimizer(1e-2).minimize(cost)\n",
    "        # self.train_op = tf.train.AdagradOptimizer(1e-2).minimize(cost)\n",
    "        # self.train_op = tf.train.MomentumOptimizer(1e-3, momentum=0.9).minimize(cost)\n",
    "        # self.train_op = tf.train.GradientDescentOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "        # create replay memory\n",
    "        self.experience = {'s': [], 'a': [], 'r': [], 's2': [], 'done': []}\n",
    "        self.max_experiences = max_experiences\n",
    "        self.min_experiences = min_experiences\n",
    "        self.batch_sz = batch_sz\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "\n",
    "    def copy_from(self, other):\n",
    "        # collect all the ops\n",
    "        ops = []\n",
    "        my_params = self.params\n",
    "        other_params = other.params\n",
    "        for p, q in zip(my_params, other_params):\n",
    "            actual = self.session.run(q)\n",
    "            op = p.assign(actual)\n",
    "            ops.append(op)\n",
    "        # now run them all\n",
    "        self.session.run(ops)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        return self.session.run(self.predict_op, feed_dict={self.X: X})\n",
    "\n",
    "    def train(self, target_network):\n",
    "        # sample a random batch from buffer, do an iteration of GD\n",
    "        if len(self.experience['s']) < self.min_experiences:\n",
    "            # don't do anything if we don't have enough experience\n",
    "            return\n",
    "\n",
    "        # randomly select a batch\n",
    "        idx = np.random.choice(len(self.experience['s']), size=self.batch_sz, replace=False)\n",
    "        # print(\"idx:\", idx)\n",
    "        states = [self.experience['s'][i] for i in idx]\n",
    "        actions = [self.experience['a'][i] for i in idx]\n",
    "        rewards = [self.experience['r'][i] for i in idx]\n",
    "        next_states = [self.experience['s2'][i] for i in idx]\n",
    "        dones = [self.experience['done'][i] for i in idx]\n",
    "        next_Q = np.max(target_network.predict(next_states), axis=1)\n",
    "        targets = [r + self.gamma*next_q if not done else r for r, next_q, done in zip(rewards, next_Q, dones)]\n",
    "\n",
    "        # call optimizer\n",
    "        self.session.run(\n",
    "          self.train_op,\n",
    "          feed_dict={\n",
    "            self.X: states,\n",
    "            self.G: targets,\n",
    "            self.actions: actions\n",
    "          }\n",
    "        )\n",
    "\n",
    "    def add_experience(self, s, a, r, s2, done):\n",
    "        if len(self.experience['s']) >= self.max_experiences:\n",
    "            self.experience['s'].pop(0)\n",
    "            self.experience['a'].pop(0)\n",
    "            self.experience['r'].pop(0)\n",
    "            self.experience['s2'].pop(0)\n",
    "            self.experience['done'].pop(0)\n",
    "            self.experience['s'].append(s)\n",
    "            self.experience['a'].append(a)\n",
    "            self.experience['r'].append(r)\n",
    "            self.experience['s2'].append(s2)\n",
    "            self.experience['done'].append(done)\n",
    "\n",
    "    def sample_action(self, x, eps):\n",
    "        if np.random.random() < eps:\n",
    "            return np.random.choice(self.K)\n",
    "        else:\n",
    "            X = np.atleast_2d(x)\n",
    "        return np.argmax(self.predict(X)[0])\n",
    "\n",
    "#end dqn\n",
    "def play_one(env, model, tmodel, eps, gamma, copy_period, learn=True):\n",
    "  \n",
    "\n",
    "    global iters\n",
    "    env.reset()\n",
    "\n",
    "    observation = env.board.copy().flatten()\n",
    "    prev_observation = observation.copy().flatten()\n",
    "        \n",
    "    done = False\n",
    "\n",
    "    totalreward = 0\n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        reward = 0\n",
    "        \n",
    "        while True:\n",
    "            #until a valid action is given\n",
    "            #action = int( input('Player 1 input') )\n",
    "            \n",
    "            action = model.sample_action(observation, eps)\n",
    "            \n",
    "            placed = env.step(who=1, action=action)\n",
    "            if placed == True:\n",
    "                break\n",
    "\n",
    "        #move has been done, environment has moved to next state, so update\n",
    "        prev_observation = observation.copy().flatten()\n",
    "        observation = env.board.copy().flatten()\n",
    "                \n",
    "        if env.isFinal() > 0:\n",
    "            done = True\n",
    "            reward = +1\n",
    "            # update the model\n",
    "            \n",
    "            model.add_experience(prev_observation, action, reward, observation, done)\n",
    "            model.train(tmodel)\n",
    "            iters += 1\n",
    "            if iters % copy_period == 0:\n",
    "                tmodel.copy_from(model)\n",
    "            break\n",
    "\n",
    "        #print(env.board)\n",
    "\n",
    "        while True:\n",
    "            #until a valid action is given\n",
    "            #action = int( input('Player 2 input') )\n",
    "            \n",
    "            #agent 2 has to take an action based on the \"reversed state\"\n",
    "            #reversed state: every 1 becomes 2 and vice versa\n",
    "            action = model.sample_action( rev(observation), eps)\n",
    "            \n",
    "            placed = env.step(who=2, action=action)\n",
    "            if placed == True:\n",
    "                break\n",
    "\n",
    "        #move has been done, environment has moved to next state, so update\n",
    "        prev_observation = observation.copy().flatten()\n",
    "        observation = env.board.copy().flatten()\n",
    "        \n",
    "        if env.isFinal() > 0:\n",
    "            done = True\n",
    "            reward = -1\n",
    "            # update the model\n",
    "            \n",
    "            if learn:\n",
    "                model.add_experience(prev_observation, action, reward, observation, done)\n",
    "                model.train(tmodel)\n",
    "                iters += 1\n",
    "                if iters % copy_period == 0:\n",
    "                    tmodel.copy_from(model)\n",
    "            break\n",
    "\n",
    "        #print(env.board)\n",
    "        \n",
    "        observation = env.board.copy().flatten()\n",
    "        \n",
    "        # update the model\n",
    "        if learn:\n",
    "            model.add_experience(prev_observation, action, reward, observation, done)\n",
    "            model.train(tmodel)\n",
    "            iters += 1\n",
    "            if iters % copy_period == 0:\n",
    "                tmodel.copy_from(model)\n",
    "\n",
    "        \n",
    "    return reward\n",
    "gamma = 0.99\n",
    "copy_period = 50\n",
    "\n",
    "D = 6*7#len(env.observation_space.sample())\n",
    "K = 7#env.action_space.n\n",
    "sizes = [512,256,128,64,64]\n",
    "model = DQN(D, K, sizes, gamma)\n",
    "tmodel = DQN(D, K, sizes, gamma)\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.InteractiveSession()\n",
    "session.run(init)\n",
    "model.set_session(session)\n",
    "tmodel.set_session(session)\n",
    "\n",
    "\n",
    "iters = 1\n",
    "\n",
    "N = 1500\n",
    "totalrewards = np.empty(N)\n",
    "costs = np.empty(N)\n",
    "avg = []\n",
    "\n",
    "begin = time.time()\n",
    "\n",
    "for n in range(N):\n",
    "    eps = 0.1#1.0/np.sqrt(n+1)\n",
    "    totalreward = play_one(env, model, tmodel, eps, gamma, copy_period)\n",
    "    totalrewards[n] = totalreward\n",
    "    #if n % 100 == 0:\n",
    "    mean_reward = totalrewards[max(0, n-100):(n+1)].mean()\n",
    "    avg.append( mean_reward )\n",
    "    print(\"episode:\", n, \"total reward:\", totalreward, \"eps:\", eps, \"avg reward (last 100):\", mean_reward )\n",
    "\n",
    "    #print( env.board)\n",
    "    \n",
    "print(\"avg reward for last 100 episodes:\", totalrewards[-100:].mean())\n",
    "print(\"total steps:\", totalrewards.sum())\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print( end - begin )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\nsingh\\AppData\\Local\\Temp\\ipykernel_24216\\2212402859.py\", line 1, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py\", line 131, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py\", line 138, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"c:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(avg)\n",
      "File \u001b[1;32mc:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:131\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32mc:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32mc:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nsingh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(avg)\n",
    "plt.title(\"Rewards\")\n",
    "plt.show()\n",
    "\n",
    "# plot_running_avg(totalrewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = [ totalrewards[max(0, n-100):(n+1)].mean() for i in range(1000) ]\n",
    "\n",
    "plt.plot(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array( [ [1,2,0,2], [2,2,1,1] ] )\n",
    "b = a.copy()\n",
    "\n",
    "print(b)\n",
    "\n",
    "\n",
    "print( rev(a) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range( env.C-3):\n",
    "    print(a[j:j+4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in range( env.C-3):\n",
    "    print(a[j:j+4] == [a[j]]*4)\n",
    "env = Environment()\n",
    "env.reset()\n",
    "env.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "root = tkinter.Toplevel()#to Tk(  )\n",
    "\n",
    "img = ImageTk.PhotoImage(Image.open(\"/Users/yeezhianliew/Downloads/Connect4-master 2/keno.png\"))\n",
    "\n",
    "keno = ImageTk.PhotoImage(Image.open(\"/Users/yeezhianliew/Downloads/Connect4-master 2/keno.png\"))\n",
    "red = ImageTk.PhotoImage(Image.open(\"/Users/yeezhianliew/Downloads/Connect4-master 2/kokkino.png\"))\n",
    "blue = ImageTk.PhotoImage(Image.open(\"/Users/yeezhianliew/Downloads/Connect4-master 2/ble.png\"))\n",
    "\n",
    "env.reset()\n",
    "\n",
    "observation = env.board.copy().flatten()\n",
    "prev_observation = observation.copy()\n",
    "\n",
    "def update_board():\n",
    "    \n",
    "    r = 0\n",
    "    c = 0\n",
    "\n",
    "    tkinter.Button(root, text='R%s/C%s'%(r,c),\n",
    "        borderwidth=1, command = lambda: helloCallBack( 0 ) ).grid(row=0,column=0)\n",
    "    tkinter.Button(root, text='R%s/C%s'%(r,c),\n",
    "        borderwidth=1, command = lambda: helloCallBack( 1 ) ).grid(row=0,column=1)\n",
    "    tkinter.Button(root, text='R%s/C%s'%(r,c),\n",
    "        borderwidth=1, command = lambda: helloCallBack( 2 ) ).grid(row=0,column=2)\n",
    "    tkinter.Button(root, text='R%s/C%s'%(r,c),\n",
    "        borderwidth=1, command = lambda: helloCallBack( 3 ) ).grid(row=0,column=3)\n",
    "    tkinter.Button(root, text='R%s/C%s'%(r,c),\n",
    "        borderwidth=1, command = lambda: helloCallBack( 4 ) ).grid(row=0,column=4)\n",
    "    tkinter.Button(root, text='R%s/C%s'%(r,c),\n",
    "        borderwidth=1, command = lambda: helloCallBack( 5 ) ).grid(row=0,column=5)\n",
    "    tkinter.Button(root, text='R%s/C%s'%(r,c),\n",
    "        borderwidth=1, command = lambda: helloCallBack( 6 ) ).grid(row=0,column=6)\n",
    "    \n",
    "    #update the board\n",
    "    for r in range(6):\n",
    "        for c in range(7):\n",
    "            if env.board[r][c] == 0:\n",
    "                cur = keno\n",
    "            elif env.board[r][c] == 1:\n",
    "                cur = red\n",
    "            else:\n",
    "                cur = blue\n",
    "                \n",
    "            tkinter.Label(root, text='R%s/C%s'%(r,c),\n",
    "                borderwidth=1, image=cur ).grid(row=r+1,column=c)\n",
    "\n",
    "def helloCallBack(value):\n",
    "    done = False\n",
    "    \n",
    "    global observation, prev_observation\n",
    "    \n",
    "    if env.isFinal() > 0:\n",
    "        return\n",
    "    \n",
    "    prev_observation = observation.copy().flatten()\n",
    "    \n",
    "    #do action\n",
    "    placed = env.step(who=1, action=value)\n",
    "    if placed == False:\n",
    "        return        \n",
    "\n",
    "    #move has been done, environment has moved to next state, so update\n",
    "    prev_observation = observation.copy().flatten()\n",
    "    observation = env.board.copy().flatten()\n",
    "\n",
    "    if env.isFinal() > 0:\n",
    "        done = True\n",
    "        print( \"CONGRATULATIONS! YOU WON! :)\")\n",
    "        update_board()\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        #until a valid action is given\n",
    "        #action = int( input('Player 2 input') )\n",
    "\n",
    "        #agent 2 has to take an action based on the \"reversed state\"\n",
    "        #reversed state: every 1 becomes 2 and vice versa\n",
    "        action = model.sample_action( rev(observation), eps)\n",
    "\n",
    "        placed = env.step(who=2, action=action)\n",
    "        if placed == True:\n",
    "            break\n",
    "\n",
    "    #move has been done, environment has moved to next state, so update\n",
    "    prev_observation = observation.copy().flatten()\n",
    "    observation = env.board.copy().flatten()\n",
    "    \n",
    "    #end of do actions\n",
    "\n",
    "    if env.isFinal() > 0:\n",
    "        done = True\n",
    "        print(\"Sorry :(, You lost!\")\n",
    "        update_board()\n",
    "        return\n",
    "        \n",
    "    #end of logic\n",
    "    \n",
    "    #update the board\n",
    "    update_board()    \n",
    "    print(value)\n",
    "    #tkMessageBox.showinfo( \"Hello Python\", \"Hello World\")\n",
    "    \n",
    "#B = Tkinter.Button(top, text =\"Hello\", command = helloCallBack)\n",
    "\n",
    "update_board()\n",
    "\n",
    "#root\n",
    "root.mainloop(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "import os\n",
    "save_path = saver.save(session, os.getcwd() + \"/\" + \"connect_4_model.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)\n",
    "\n",
    "\n",
    "#saver.restore(session, \"\")\n",
    "saver.restore(session, os.getcwd() + \"/\" + \"connect_4_model.ckpt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
